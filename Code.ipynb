{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  label  \n",
       "0      8.8      0  \n",
       "1      9.5      0  \n",
       "2     10.1      0  \n",
       "3      9.9      0  \n",
       "4      9.9      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"wine-dataset.csv\") #reading the file\n",
    "#renaming the files helps later during the processing stage\n",
    "df = df.rename(columns={\"quality\": \"label\"})\n",
    "df = df.rename(columns={\"fixed acidity\": \"fixed_acidity\"})\n",
    "df = df.rename(columns={\"volatile acidity\": \"volatile_acidity\"})\n",
    "df = df.rename(columns={\"citric acid\": \"citric_acid\"})\n",
    "df = df.rename(columns={\"residual sugar\": \"residual_sugar\"})\n",
    "df = df.rename(columns={\"free sulfur dioxide\": \"free_sulfur_dioxide\"})\n",
    "df = df.rename(columns={\"total sulfur dioxide\": \"total_sulfur_dioxide\"})\n",
    "\n",
    "df.head() #this will show the top 5 elements of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if the Data is Pure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity_check(data):\n",
    "    \n",
    "    return len(np.unique(data[:, -1])) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Potential Splits and Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(data):\n",
    "    \n",
    "    uni_class, counts_uni_class = np.unique(data[:, -1], return_counts=True) #returns the unique classes as well as their counts\n",
    "    return uni_class[counts_uni_class.argmax()] #returns the class with majority count\n",
    "\n",
    "def get_potential_splits(data):\n",
    "    \n",
    "    pot_spl = dict()\n",
    "    rows , cols = data.shape\n",
    "    for ind in range(cols - 1):          # excluding the last column as it as label\n",
    "        pot_spl[ind] = np.unique(data[:, ind])\n",
    "    \n",
    "    return pot_spl #returns the potential splits\n",
    "\n",
    "def split(data, col, val):\n",
    "    #splits the data on the basis of particular column and value\n",
    "    left_split = data[data[:, col] <= val] #data with values less \n",
    "    right_split = data[data[:, col] >  val] #data with values more\n",
    "    \n",
    "    return left_split, right_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Calculating the entropy and Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(data):\n",
    "    \n",
    "    classes , counts = np.unique(data[:, -1], return_counts=True)\n",
    "    prob = counts / counts.sum() #calc prob for each of the unique classes\n",
    "    entropy = sum(prob * -np.log2(prob)) #entropy calc formula\n",
    "     \n",
    "    return entropy\n",
    "\n",
    "def gini(data):\n",
    "    \n",
    "    impurity=1\n",
    "    _, counts = np.unique(data[:, -1], return_counts=True)\n",
    "    prob = counts / counts.sum() #calc prob for each of the unique classes\n",
    "    for x in prob:\n",
    "        impurity -= x**2 #gini index calc formula\n",
    "     \n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Calculating the Information Gain and Finding best splits possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_info_gain_gini(left_split, right_split,uncertainity):\n",
    "    \n",
    "    total=len(left_split) + len(right_split) #total number of records\n",
    "    #calc prob for the splits\n",
    "    prob_left = len(left_split) / total\n",
    "    prob_right = len(right_split) / total\n",
    "\n",
    "    return uncertainity -  (prob_left * gini(left_split) + prob_right * gini(right_split))\n",
    "\n",
    "def calculate_info_gain_entropy(left_split, right_split ,uncertainity):\n",
    "    \n",
    "    total=len(left_split) + len(right_split) #total number of records\n",
    "    #calc prob for the splits\n",
    "    prob_left = len(left_split) / total\n",
    "    prob_right = len(right_split) / total\n",
    "\n",
    "    return uncertainity -  (prob_left * calc_entropy(left_split) + prob_right * calc_entropy(right_split))\n",
    "\n",
    "def find_best_split(data, pot_spl, method):\n",
    "    \n",
    "    if method==0: #if method = 0 means we want entropy\n",
    "        uncertainity=calc_entropy(data)\n",
    "    else:\n",
    "        uncertainity=gini(data) #if method = 1 means we want gini index\n",
    "        \n",
    "    overall_info_gain = 0\n",
    "    for col in pot_spl:\n",
    "        for val in pot_spl[col]:\n",
    "            left_split, right_split = split(data, col, val)\n",
    "            if method==0: #entropy\n",
    "                current_info_gain = calculate_info_gain_entropy(left_split, right_split, uncertainity)\n",
    "            else: #gini index\n",
    "                current_info_gain = calculate_info_gain_gini(left_split, right_split, uncertainity)\n",
    "\n",
    "            if current_info_gain > overall_info_gain:\n",
    "                overall_info_gain = current_info_gain\n",
    "                best_col = col\n",
    "                best_val = val\n",
    "    \n",
    "    return best_col, best_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representation of a node in the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = {\"question\": [\"yes_answer\", \n",
    "                         \"no_answer\"]}\n",
    "column_names = df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Algorithm without Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, method, count=0):\n",
    "    \n",
    "    data = df\n",
    "    if count == 0:\n",
    "        data = df.values #convert from dataframe to numpy list of lists         \n",
    "    \n",
    "    # base case\n",
    "    if (purity_check(data)):\n",
    "        return get_class(data) #return the class\n",
    "  \n",
    "    count += 1\n",
    "\n",
    "    pot_spl = get_potential_splits(data)\n",
    "    col, val = find_best_split(data, pot_spl,method)\n",
    "    left_split, right_split = split(data, col, val)\n",
    "        \n",
    "        # check for empty splits\n",
    "    if len(left_split) == len(right_split) == 0:\n",
    "        return get_class(data)\n",
    "        \n",
    "        # determine the question\n",
    "    attribute = column_names[col]\n",
    "    ques = f'{attribute} <= {val}'\n",
    "        \n",
    "        # recursive calls\n",
    "    success = decision_tree_algorithm(left_split,method, count)\n",
    "    failure = decision_tree_algorithm(right_split,method, count)\n",
    "    \n",
    "    # subtree structure\n",
    "    node = {ques: []}\n",
    "    \n",
    "    if success == failure:\n",
    "        node = failure\n",
    "    else:\n",
    "        node[ques].append(success)\n",
    "        node[ques].append(failure)\n",
    "        \n",
    "    return node\n",
    "\n",
    "def classification(eg, tree):\n",
    "    \n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    \n",
    "    ques = list(tree.keys())[0]\n",
    "    attribute , comparison_operator, val = ques.split()\n",
    "\n",
    "    if eg[attribute] <= float(val):\n",
    "        res = tree[ques][0]\n",
    "    else:\n",
    "        res = tree[ques][1]\n",
    "\n",
    "    return classification(eg, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for calculating the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df, tree):\n",
    "\n",
    "    df[\"predictions\"] = df.apply(classification, args=(tree,), axis=1 , raw=False )\n",
    "    df[\"comparison\"] = df[\"predictions\"] == df[\"label\"]\n",
    "    \n",
    "    return df[\"comparison\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation with and without Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KFoldCross_with_random_sampling(df,splits,method):\n",
    "    accuracy_scores=[]\n",
    "    fold_size=round(len(df)/splits)\n",
    "    indices = df.index.tolist()\n",
    "    \n",
    "    for k in range(splits):\n",
    "        test_indices = random.sample(population=indices, k=fold_size)\n",
    "        test_data = df.loc[test_indices]\n",
    "        train_data = df.drop(test_indices)\n",
    "        \n",
    "        tree = decision_tree_algorithm(train_data ,method)\n",
    "        test_accuracy = calculate_accuracy(test_data, tree)*100\n",
    "        \n",
    "        accuracy_scores.append(test_accuracy)\n",
    "        \n",
    "    return accuracy_scores\n",
    "\n",
    "\n",
    "def KFoldCross_without_random_sampling(df,splits,method):\n",
    "    \n",
    "    indices=df.index.tolist()\n",
    "    fold_size=round(len(df)/splits)\n",
    "    index=0\n",
    "    accuracy_scores=[]\n",
    "        \n",
    "    for k in range(splits):\n",
    "        test_indices=[]\n",
    "        while len(test_indices)<fold_size and index < len(df):\n",
    "            test_indices.append(index)\n",
    "            index+=1\n",
    "        \n",
    "        test_data = df.loc[test_indices]\n",
    "        train_data = df.drop(test_indices)\n",
    "        \n",
    "        tree = decision_tree_algorithm(train_data,method)\n",
    "        test_accuracy = calculate_accuracy(test_data, tree)*100\n",
    "        \n",
    "        accuracy_scores.append(test_accuracy)\n",
    "        \n",
    "    return accuracy_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the Accuracy using K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using KFold without Random Sampling: 74.90715958514554\n",
      "Accuracy using KFold with Random Sampling: 84.06122448979592\n"
     ]
    }
   ],
   "source": [
    "#executing this cell may take 2-3 minutes\n",
    "accuracy_without_random = KFoldCross_without_random_sampling(df,10,0)#0 means using entropy\n",
    "print(\"Accuracy using KFold without Random Sampling: {}\".format(np.mean(accuracy_without_random)))\n",
    "\n",
    "accuracy_with_random = KFoldCross_with_random_sampling(df,10,0) #0 means using entropy \n",
    "print(\"Accuracy using KFold with Random Sampling: {}\".format(np.mean(accuracy_with_random)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvement Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using Gini Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The KFoldCrossVal Accuracy using Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using KFold with Random Sampling and Gini: 83.22448979591836\n"
     ]
    }
   ],
   "source": [
    "accuracy_with_random = KFoldCross_with_random_sampling(df,10,1) #1 means using gini\n",
    "print(\"Accuracy using KFold with Random Sampling and Gini: {}\".format(np.mean(accuracy_with_random)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruned_decision_tree_algorithm(df, method, count=0, threshold=2, max_depth=20):\n",
    "    \n",
    "    data = df\n",
    "    if count == 0:\n",
    "        data = df.values         \n",
    "    \n",
    "    # base case\n",
    "    if (purity_check(data) | (len(data) < threshold) | (count == max_depth)): #if data is pure, threshold is reached or max_depth reached\n",
    "        return get_class(data)\n",
    "  \n",
    "    count += 1 #incrementing the counter\n",
    "    \n",
    "    #determining the left and right split using the best split possible\n",
    "    pot_spl = get_potential_splits(data)\n",
    "    col, val = find_best_split(data, pot_spl,method)\n",
    "    left_split, right_split = split(data, col, val)\n",
    "        \n",
    "        # check for empty splits\n",
    "    if len(left_split) == len(right_split) == 0:\n",
    "        return get_class(data)\n",
    "        \n",
    "        # determine the question\n",
    "    attribute = column_names[col]\n",
    "    ques = f'{attribute} <= {val}'\n",
    "        \n",
    "        # recursive calls\n",
    "    success = pruned_decision_tree_algorithm(left_split,method, count, threshold, max_depth)\n",
    "    failure = pruned_decision_tree_algorithm(right_split,method, count, threshold, max_depth)\n",
    "    \n",
    "     # subtree structure\n",
    "    node = {ques: []}\n",
    "    \n",
    "    if success == failure:\n",
    "        node = failure\n",
    "    else:\n",
    "        node[ques].append(success)\n",
    "        node[ques].append(failure)\n",
    "        \n",
    "    return node\n",
    "\n",
    "def KFoldCross_with_Pruning(df,splits,method):\n",
    "    accuracy_scores=[]\n",
    "    fold_size=round(len(df)/splits)\n",
    "    indices = df.index.tolist()\n",
    "    \n",
    "    for k in range(splits):\n",
    "        test_indices = random.sample(population=indices, k=fold_size)\n",
    "        test_data = df.loc[test_indices]\n",
    "        train_data = df.drop(test_indices)\n",
    "        \n",
    "        tree = pruned_decision_tree_algorithm(train_data ,method,max_depth=20)\n",
    "        test_accuracy = calculate_accuracy(test_data, tree)*100\n",
    "        \n",
    "        accuracy_scores.append(test_accuracy)\n",
    "        \n",
    "    return accuracy_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold CrossVal Accuracy using Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using KFold with Pruning: 84.22448979591836\n"
     ]
    }
   ],
   "source": [
    "#executing this cell may take 2-3 minutes\n",
    "accuracy_with_pruning = KFoldCross_with_Pruning(df,10,0)\n",
    "print(\"Accuracy using KFold with Pruning: {}\".format(np.mean(accuracy_with_pruning)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation of the decision tree after Pruning(till depth 3) using Entropy and Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Representation using Entropy\n",
      "{'alcohol <= 10.6': [0.0,\n",
      "                     {'alcohol <= 11.7333333333333': [0.0,\n",
      "                                                      {'free_sulfur_dioxide <= 21.0': [0.0,\n",
      "                                                                                       1.0]}]}]}\n",
      "\n",
      "\n",
      "Decision Tree Representation using Gini\n",
      "{'alcohol <= 10.8': [{'volatile_acidity <= 0.2': [{'density <= 0.99784': [0.0,\n",
      "                                                                          1.0]},\n",
      "                                                  0.0]},\n",
      "                     {'alcohol <= 12.5': [0.0,\n",
      "                                          {'free_sulfur_dioxide <= 20.0': [0.0,\n",
      "                                                                           1.0]}]}]}\n"
     ]
    }
   ],
   "source": [
    "#method=0 means we are constructing the decision tree using entropy\n",
    "print('Decision Tree Representation using Entropy')\n",
    "tree=pruned_decision_tree_algorithm(df,method=0,max_depth=3)\n",
    "pprint(tree)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "#method=1 means we are constructing the decision tree using gini\n",
    "print('Decision Tree Representation using Gini')\n",
    "tree=pruned_decision_tree_algorithm(df,method=1,max_depth=3)\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
